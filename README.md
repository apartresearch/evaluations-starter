# Get started with model evaluation research

Model evaluation is a technical field of AI safety and ML research focused on benchmarking and evaluating models. Sub-fields include Benchmarking, Dangerous Capability Evaluations, and Demonstrations. Related research topics include the governance of AI, alignment research, and scenario planning for AI.

This is a short overview of introductory material available in the field of model evaluations and will work as a guide for you to engage with the field.

_This is a work in progress and we invite interested parties to submit pull requests for new materials_

## Demonstrations research

### Demonstrating risks to institutional fragility from AI

[Visit to the democracy x AI hackathon](https://www.apartresearch.com/event/ai-democracy) where material for demonstrating and extrapolating risks to society from AI is the main topic.

Project examples include developing an LLM to contain a sleeper agent that activates on election day, training agents to skew poll results to inflate support for particular policies, or using an LLM to draft uncontroversial legislative proposals that, if implemented, indirectly impacts more contentious or harmful policies.

These are ideas to get you started and you can [check out the results](https://apartresearch.com/sprints#research) from previous hackathons to see examples of the types of projects you can develop during just one weekend, e.g. [EscalAItion](https://www.apartresearch.com/project/escalation-assessing-multi-agent-risks-in-military-contexts) found that LLMs had a propensity to escalate in military scenarios and was [accepted](https://openreview.net/forum?id=5HuBX8LvuT&utm_source=updates.apartresearch.com&utm_medium=referral&utm_campaign=apart-s-2023-wrapping-up-a-great-year) at the multi-agent security workshop at NeurIPS 2023 after further development.

### **Inspiration**

Here is some interesting material to get inspiration for the hackathon:

- [A paper presenting a framework for AI and Democracy](https://journals.sagepub.com/doi/pdf/10.1177/20563051231186353)
- [Article by Yoshua Bengio in the Journal of Democracy](https://www.journalofdemocracy.org/ai-and-catastrophic-risk/)
- [Why it Matters podcast on The Year of AI and Elections](https://podcasts.apple.com/gb/podcast/the-year-of-ai-and-elections/id1482132871?i=1000639276052)
- [Guardian article about the influence of AI on the US elections](https://www.theguardian.com/us-news/2024/feb/26/ai-deepfakes-disinformation-election)
- [80000 hours podcast with Nina Schick on disinformation and the rise of synthetic media](https://80000hours.org/podcast/episodes/nina-schick-disinformation-synthetic-media/)
