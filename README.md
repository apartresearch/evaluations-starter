# evaluations-starter
How to get started in evaluations and demonstrations research for dangerous capabilities

## Demonstrations research

### Demonstrating risks to institutional fragility from AI

[Visit to the democracy x AI hackathon](https://www.apartresearch.com/event/ai-democracy).

You can check out a bunch of interesting ideas on [AI Safety Ideas](https://aisafetyideas.com/list/ai-x-democracy-hackathon) to redteam democracy by creating a demonstration of an actual risk model. For example, you could finetune an opensource LLM to contain a sleeper agent that activates on election day. Or use an LLM to draft legislative proposals that appear to address uncontroversial issues but are crafted in such a way that their implementation indirectly impacts more contentious or harmful policies.

Also [check out the results](https://apartresearch.com/sprints#research) from previous hackathons to see what you might accomplish during just one weekend!

### **Inspiration**

-   Here is some interesting material to get inspiration for the hackathon:
    -   [A paper presenting a framework for AI and Democracy](https://journals.sagepub.com/doi/pdf/10.1177/20563051231186353)
    -   [Article by Yoshua Bengio in the Journal of Democracy](https://www.journalofdemocracy.org/ai-and-catastrophic-risk/)
    -   [Podcast about the risks of AI for democracy](https://www.everand.com/listen/podcast/653587405)
